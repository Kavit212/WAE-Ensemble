{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WAE-Net Grad-CAM Ensemble.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbnkMEixv4VtJhKsUp59Ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavit212/WAE-Ensemble/blob/main/WAE_Net_Grad_CAM_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3UYW3y2ycdj"
      },
      "outputs": [],
      "source": [
        "#Install required software and dependencies\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.2.4\n",
        "!pip install git+https://github.com/Kavit212/SegGradCAM\n",
        "!pip install h5py==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import sys\n",
        "import keras\n",
        "import datetime \n",
        "import json\n",
        "import collections\n",
        "import tqdm\n",
        "import imageio\n",
        "import scipy\n",
        "import operator\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "import skimage\n",
        "import csbdeep"
      ],
      "metadata": {
        "id": "-NSEMnbsyiRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Version check\n",
        "\n",
        "print(np.__version__)\n",
        "#print(os.__version__)\n",
        "#print(pathlib.__version__)\n",
        "#print(sys.__version__)\n",
        "print(keras.__version__)\n",
        "#print(datetime .__version__)\n",
        "print(json.__version__)\n",
        "#print(collections.__version__)\n",
        "print(tqdm.__version__)\n",
        "print(imageio.__version__)\n",
        "print(scipy.__version__)\n",
        "#print(operator.__version__)\n",
        "print(pd.__version__)\n",
        "print(cv2.__version__)\n",
        "#print(K.__version__)\n",
        "print(skimage.__version__)\n",
        "print(csbdeep.__version__)"
      ],
      "metadata": {
        "id": "BgyzP53EzYcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "UeT1M3mjzfYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Kavit212/SegGradCAM\n",
        "%cd SegGradCAM"
      ],
      "metadata": {
        "id": "NWKrgoW-zjna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "metadata": {
        "id": "C0M48zaAzkNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import segmentation_models as sm\n",
        "\n",
        "from seggradcam.dataloaders import Cityscapes\n",
        "#from metrics import iou_coef, dice_coef, dice_loss\n",
        "from seggradcam.unet import csbd_unet, manual_unet, TrainUnet\n",
        "from seggradcam.training_write import TrainingParameters, TrainingResults\n",
        "from seggradcam.training_plots import plot_predict_and_gt, plot_loss, plot_metric\n",
        "from seggradcam.seggradcam import SegGradCAM, SuperRoI, ClassRoI, PixelRoI, BiasRoI\n",
        "from seggradcam.visualize_sgc import SegGradCAMplot"
      ],
      "metadata": {
        "id": "il1CjhZTzmD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing images, if needed\n",
        "#Change number of classes if needed\n",
        "SIZE_X = 512\n",
        "SIZE_Y = 512\n",
        "#Number of classes for segmentation\n",
        "n_classes = 3"
      ],
      "metadata": {
        "id": "rg3yQkL30Bj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture training image info as a list\n",
        "train_images = []\n",
        "\n",
        "for directory_path in glob.glob(\"Please enter augmented training images path\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        img = cv2.imread(img_path, 1)       \n",
        "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "        train_images.append(img)\n",
        "       \n",
        "#Convert list to array for machine learning processing        \n",
        "train_images = np.array(train_images)\n",
        "\n",
        "#Capture mask/label info as a list\n",
        "train_masks = [] \n",
        "for directory_path in glob.glob(\"Please enter augmented training masks path\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        mask = cv2.imread(mask_path, 0)       \n",
        "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
        "        train_masks.append(mask)\n",
        "        \n",
        "#Convert list to array for machine learning processing          \n",
        "train_masks = np.array(train_masks)"
      ],
      "metadata": {
        "id": "td3upD5_0hGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture test image info as a list\n",
        "test_images = []\n",
        "\n",
        "for directory_path in glob.glob(\"Please enter test images path\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        img = cv2.imread(img_path, 1)       \n",
        "        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "        test_images.append(img)\n",
        "       \n",
        "#Convert list to array for machine learning processing        \n",
        "test_images = np.array(test_images)\n",
        "\n",
        "#Capture mask/label info as a list\n",
        "test_masks = [] \n",
        "for directory_path in glob.glob(\"Please enter test masks path\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        mask = cv2.imread(mask_path, 0)       \n",
        "        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
        "        test_masks.append(mask)\n",
        "        \n",
        "#Convert list to array for machine learning processing          \n",
        "test_masks = np.array(test_masks)"
      ],
      "metadata": {
        "id": "1mvvZygR0rmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "#Encode labels. It is multi dimension array, so we flatten, encode and reshape\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "n, h, w = train_masks.shape\n",
        "train_masks_reshaped = train_masks.reshape(-1,1)\n",
        "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
        "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "np.unique(train_masks_encoded_original_shape)"
      ],
      "metadata": {
        "id": "gw69iM2t0vkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "#Encode labels. It is multi dimension array, so we flatten, encode and reshape\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "n, h, w = test_masks.shape\n",
        "test_masks_reshaped = test_masks.reshape(-1,1)\n",
        "test_masks_reshaped_encoded = labelencoder.fit_transform(test_masks_reshaped)\n",
        "test_masks_encoded_original_shape = test_masks_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "np.unique(test_masks_encoded_original_shape)"
      ],
      "metadata": {
        "id": "PoYf6hor0xh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)\n",
        "test_masks_input = np.expand_dims(test_masks_encoded_original_shape, axis=3)"
      ],
      "metadata": {
        "id": "4wzYdmVj0zur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_images\n",
        "y_train = train_masks_input\n",
        "X_test = test_images\n",
        "y_test = test_masks_input\n",
        "\n",
        "\n",
        "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/ unlabeled class"
      ],
      "metadata": {
        "id": "H8Mw2XNh00bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.utils import to_categorical\n",
        "train_masks_cat = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
        "\n",
        "\n",
        "test_masks_cat = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
        "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n"
      ],
      "metadata": {
        "id": "eqS0L_uN02rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reused parameters in all models\n",
        "#Number of classes and class weight are changed according to the dataset \n",
        "\n",
        "n_classes=3\n",
        "activation='softmax'\n",
        "\n",
        "LR = 0.0001\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "\n",
        "# set class weights for dice_loss according to number of classes \n",
        "#dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25]))\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.33, 0.33, 0.33]))  \n",
        "#dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.2, 0.2, 0.2, 0.2, 0.2]))\n",
        "#dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
      ],
      "metadata": {
        "id": "47jFLPy709Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Calbacks\n",
        "# If required, please use one CSV log path for each of the models\n",
        "\n",
        "csv_logger1 = tf.keras.callbacks.CSVLogger('Please enter your intended callback path', append=False, separator=',')\n",
        "csv_logger2 = tf.keras.callbacks.CSVLogger('Please enter your intended callback path', append=False, separator=',')\n",
        "csv_logger3 = tf.keras.callbacks.CSVLogger'Please enter your intended callback path', append=False, separator=',')\n",
        "csv_logger4 = tf.keras.callbacks.CSVLogger('Please enter your intended callback path', append=False, separator=',')\n",
        "csv_logger5 = tf.keras.callbacks.CSVLogger('Please enter your intended callback path', append=False, separator=',')\n",
        "\n",
        "# Other callbacks used for all models\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=10, mode='min', verbose=0)\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')"
      ],
      "metadata": {
        "id": "eOWFrQwx0_YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################\n",
        "###Model 1\n",
        "BACKBONE1 = 'resnet34'\n",
        "\n",
        "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
        "\n",
        "# preprocess input\n",
        "X_train1 = preprocess_input1(X_train)\n",
        "X_test1 = preprocess_input1(X_test)\n",
        "\n",
        "# define model\n",
        "model1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "model1.compile(optim, total_loss, metrics=metrics)\n",
        "\n",
        "\n",
        "#print(model1.summary())\n",
        "\n",
        "###Only train model if pre-trained networks are not available. \n",
        "###If pre-trained model is available, please load the model without any training\n",
        "\n",
        "#history1=model1.fit(X_train1, \n",
        "          #y_train_cat,\n",
        "          #batch_size=8, \n",
        "          #epochs=500,\n",
        "         #verbose=1,\n",
        "          #callbacks=[earlyStopping, reduce_lr, csv_logger1],\n",
        "          #validation_data=(X_test1, y_test_cat))\n",
        "\n",
        "\n",
        "#model1.save('Please enter intended path for saved model')"
      ],
      "metadata": {
        "id": "eRJxGYho1CXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('Please enter your pre-trained weight path')"
      ],
      "metadata": {
        "id": "hbtuhHNq1XkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the last convolutional layer before output\n",
        "# We recommend users to also try other layers according to your preference\n",
        "\n",
        "prop_from_layer = model.layers[-1].name\n",
        "prop_to_layer = 'decoder_stage4b_relu'\n"
      ],
      "metadata": {
        "id": "MBT3VhTj1v3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class 0 = background\n",
        "# class 1 = cell membrane\n",
        "# class 2 = nucleus /chromosomes\n",
        "# class 3 = mitochondria\n",
        "\n",
        "cls = 0 \n",
        "\n",
        "import cv2\n",
        "  \n",
        "# path\n",
        "path = r'Please enter test image path'\n",
        "  \n",
        "# Using cv2.imread() method\n",
        "# Using 0 to read image in grayscale mode\n",
        "img = cv2.imread(path, 1)\n",
        "\n",
        "#Remove hash when normally processing\n",
        "#test_img_number = 1\n",
        "#test_img = X_test[test_img_number]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Testing Image')\n",
        "#plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "\n",
        "clsroi = ClassRoI(model=model,image=image,cls=cls)\n",
        "newsgc = SegGradCAM(model, image, cls, prop_to_layer,  prop_from_layer, roi=clsroi,\n",
        "                 normalize=True, abs_w=False, posit_w=False)\n",
        "\n",
        "newsgc.SGC()\n",
        "\n",
        "# create an object with plotting functionality\n",
        "plotter = SegGradCAMplot(newsgc,model=model,n_classes=n_classes)\n",
        "\n",
        "# plot explanations on 1 picture\n",
        "#plotter.explainClass()\n",
        "plotter.explainClass()\n"
      ],
      "metadata": {
        "id": "7jSfv1S42LrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}